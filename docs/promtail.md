# ğŸ¾ Promtail Config untuk Scrape Docker Logs dengan Label

Ini adalah penjelasan per bagian dari konfigurasi `promtail.yaml` kamu ğŸ‘‡

---

## ğŸ§© Bagian 1: Server & Posisi Log

```yaml
server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml
````

* ğŸ”Œ **`http_listen_port: 9080`** â†’ UI Promtail bisa diakses di port ini.
* ğŸš« **`grpc_listen_port: 0`** â†’ gRPC dinonaktifkan (nggak dipakai).
* ğŸ“ **`positions`** â†’ Menyimpan posisi terakhir yang dibaca (biar log nggak dibaca ulang terus).

---

## ğŸ“¡ Bagian 2: Push Log ke Loki

```yaml
clients:
  - url: http://loki:3100/loki/api/v1/push
```

* ğŸš€ Promtail akan push log ke Loki melalui endpoint ini.

---

## ğŸ•µï¸â€â™‚ï¸ Bagian 3: Scrape Docker Log Berdasarkan Label

```yaml
scrape_configs:
  - job_name: flog_scrape
    docker_sd_configs:
      - host: unix:///var/run/docker.sock
        refresh_interval: 5s
        filters:
          - name: label
            values: ["logging=promtail"]
```

* ğŸ” **Docker autodiscovery** â†’ Scan container lewat Docker socket.
* â±ï¸ **refresh\_interval: 5s** â†’ Cek container baru setiap 5 detik.
* ğŸ·ï¸ **Filter label** â†’ Hanya container dengan label `logging=promtail` yang discrape.

---

## ğŸ·ï¸ Bagian 4: Relabel Metadata Container

```yaml
    relabel_configs:
      - source_labels: ['__meta_docker_container_name']
        regex: '/(.*)'
        target_label: 'container'

      - source_labels: ['__meta_docker_container_log_stream']
        target_label: 'logstream'

      - source_labels: ['__meta_docker_container_label_logging_jobname']
        target_label: 'job'

      - source_labels: ['__meta_docker_container_log_path']
        target_label: '__path__'

      - source_labels: ['__meta_docker_container_label_com_docker_compose_project']
        target_label: 'namespace'
```

* ğŸ§  Menyulap metadata Docker jadi label yang bisa di-query di Grafana:

  * ğŸ†” `container` â†’ nama container
  * ğŸ’§ `logstream` â†’ stdout/stderr
  * ğŸ”¨ `job` â†’ dari label `logging_jobname`
  * ğŸ“ `__path__` â†’ lokasi log file container
  * ğŸ§± `namespace` â†’ nama project dari docker-compose

---

## ğŸ”¬ Bagian 5: Pipeline Processing

#### ğŸ“Œ Penjelasan Singkat

- json: â†’ extract key-value dari log JSON
- timestamp: â†’ gunakan timestamp di log sebagai waktu log
- match: â†’ drop log kalau ada "GET /healthz" di log
- labels: â†’ menjadikan event dan level sebagai label Loki, bisa kamu filter via {level="error"} di Grafana

```yaml
    pipeline_stages:
      - json:
          expressions:
            loop_id: ""
            event: ""
            endpoint: ""
            timestamp: ""

      - timestamp:
          source: timestamp
          format: RFC3339Nano
```

* ğŸª„ **`json`** â†’ Ekstrak field dari log JSON (tanpa menjadikan label).
* â° **`timestamp`** â†’ Ambil waktu dari isi log (`timestamp`), bukan waktu scrape.

---

## ğŸ§¹ Bagian 6: Filter Log yang Tidak Penting

```yaml
      - match:
          selector: '{job="flog_scrape"}'
          stages:
            - drop:
                expression: "GET /healthz"
```

* ğŸ§½ Buang log yang mengandung `GET /healthz` dari job `flog_scrape` â†’ Biasanya noise dari health check.

---


* Mau bisa query log lebih granular? Tambahkan block `labels:` setelah `json` stage:

  ```yaml
  - labels:
      event: ""
      level: ""
  ```
* Hindari menjadikan `loop_id`, `timestamp`, atau data yang unik sebagai label â†’ bikin cardinality tinggi dan Grafana/Loki jadi berat.


---

âœ… **Final Thoughts:**
Konfigurasi ini **sudah clean, production-ready, dan scalable** buat observasi container Python yang logging structured JSON.
